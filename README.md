# Mental Health Ideation Detection

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0-red.svg)](https://pytorch.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Railway](https://img.shields.io/badge/Deployed%20on-Railway-blueviolet)](https://railway.app)

> **A complete machine learning system for detecting suicide ideation in text, designed for both rigorous academic research and real-world production deployment to help teachers identify at-risk students.**

ğŸš€ **[Live Demo](https://mentalhealthideation.com)** | ğŸ“š **[Documentation](docs/)** | ğŸ”¬ **[Research](research/)**

---

## ğŸ¯ Inspiration

Suicide ideation detection has critical safety implications - missing actual cases (false negatives) can be life-threatening. Teachers and educators are often on the front lines but lack tools to help them identify at-risk students early. We were inspired to create a solution that:

- **Empowers educators** with AI-assisted early detection capabilities
- **Combines rigorous research** with practical real-world deployment
- **Continuously improves** through teacher feedback and model retraining
- **Respects privacy** while providing actionable insights

This project bridges the gap between academic machine learning research and a production-ready tool that can genuinely help save lives.

---

## ğŸ’¡ What It Does

**Mental Health Ideation** is a dual-purpose system:

### ğŸŒ For Teachers (Production System)
A web application deployed at **[mentalhealthideation.com](https://mentalhealthideation.com)** that:
- âœ… Analyzes student essays in real-time for suicide ideation
- âœ… Provides risk levels (LOW/MEDIUM/HIGH) with confidence scores
- âœ… Highlights problematic text using AI interpretability (Integrated Gradients)
- âœ… Collects teacher feedback for continuous model improvement
- âœ… Includes admin dashboard for monitoring and analytics
- âœ… Automatically retrains the model based on real-world corrections

### ğŸ”¬ For Researchers (Research Pipeline)
A comprehensive ML research project that:
- âœ… Benchmarks 6+ transformer models (DistilBERT, BERT, RoBERTa, ELECTRA, XLNet, DeBERTa)
- âœ… Uses a 232,074-sample perfectly balanced dataset
- âœ… Employs rigorous methodology suitable for academic publication
- âœ… Includes statistical validation, error analysis, and interpretability studies
- âœ… Tracks experiments with Weights & Biases
- âœ… Ensures reproducibility with multiple random seeds

**Key Metrics**: False Negative Rate (most critical), F1 Score, Recall, Precision, Accuracy

---

## ğŸ› ï¸ How We Built It

### Tech Stack

**Backend & ML**
- **FastAPI** (Python 3.11) - Async API with automatic documentation
- **PyTorch + HuggingFace Transformers** - Transformer model training and inference
- **DistilBERT** - Production model (66M parameters, 255MB)
- **Celery + Redis** - Background tasks and model retraining queue

**Database & Storage**
- **PostgreSQL** - Persistence for predictions, feedback, and retraining history
- **SQLAlchemy ORM** - Database layer with migration support
- **Google Drive** - Model storage and download

**Deployment & Infrastructure**
- **Railway** - Cloud hosting with automatic CI/CD
- **Docker** - Containerization for consistency
- **Docker Compose** - Local development environment
- **Uvicorn** - ASGI server for production

**Research Tools**
- **Google Colab Pro** - GPU-accelerated model training (24hr sessions)
- **Weights & Biases** - Experiment tracking and visualization
- **SHAP/LIME** - Model interpretability
- **Scikit-learn** - Traditional baselines and metrics

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Railway Platform                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  Web Service â”‚â”€â”€â”€â”€â”€â”€â”‚   Redis   â”‚                â”‚
â”‚  â”‚  (FastAPI)   â”‚      â”‚  (Queue)  â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                â”‚
â”‚         â”‚                    â”‚                       â”‚
â”‚         â”‚  Celery Queue      â”‚                       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
â”‚                              â–¼                       â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚                  â”‚  Celery Worker    â”‚               â”‚
â”‚                  â”‚  (Model Retrain)  â”‚               â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                              â”‚                       â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚                  â”‚   PostgreSQL DB       â”‚           â”‚
â”‚                  â”‚ (Predictions/Feedback)â”‚           â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dataset
- **Size**: 232,074 samples from social media (Reddit/Twitter)
- **Balance**: Perfect 50/50 split (no class imbalance!)
- **Split**: 80/10/10 stratified train/validation/test
- **Preprocessing**: Tokenized with max length 256 (covers 80.7% of samples)

---

## ğŸš§ Challenges We Ran Into

1. **Project Consolidation**: Started with 3 conflicting project directories (~10GB total) with duplicated code and configs. Consolidated into one unified structure separating research from deployment.

2. **Model Size Constraints**: The DistilBERT model (255MB) exceeded typical deployment limits. Solved by implementing a Google Drive download strategy during Railway build process.

3. **Database Migration Complexity**: Transitioning from SQLite (development) to PostgreSQL (production) required complete rewrite of the database layer using SQLAlchemy ORM while maintaining data integrity.

4. **Feedback Loop Architecture**: Building a production-grade continuous improvement system required designing complex async task queuing with Celery, background model retraining, and safe model swapping without downtime.

5. **Token Length Optimization**: Balancing model coverage (80.7% at 256 tokens) vs. training speed (4x faster than 512 tokens) required careful analysis of token distribution statistics.

6. **Flask to FastAPI Migration**: Completely rewrote the API from Flask to FastAPI for better async support, automatic OpenAPI documentation, and production scalability.

7. **Deployment Reliability**: Ensuring model downloads work consistently on Railway, handling cold starts, managing memory constraints (512MB limit), and implementing proper health checks.

---

## ğŸ† Accomplishments That We're Proud Of

- âœ… **Clean, Balanced Dataset**: 232K samples with perfect 50/50 class distribution - no class weights needed!
- âœ… **Live Production System**: Fully deployed at mentalhealthideation.com with Railway hosting
- âœ… **Comprehensive Documentation**: Complete research plan, deployment guides, API docs
- âœ… **Modular Architecture**: Clean separation between research experimentation and production deployment
- âœ… **Continuous Improvement**: Teachers can correct predictions, enabling real-world model improvement
- âœ… **Model Interpretability**: Integrated Gradients provides visual explanations of predictions
- âœ… **Rigorous Methodology**: Statistical validation, error analysis, reproducibility with multiple seeds
- âœ… **Industry-Grade Stack**: Docker, Celery workers, PostgreSQL, Redis - production-ready infrastructure
- âœ… **Baseline Model Trained**: DistilBERT achieving strong performance, ready for benchmarking
- âœ… **Consolidated Codebase**: From messy 3-project setup to clean unified repository

---

## ğŸ“š What We Learned

1. **Research vs. Production Are Different**: Academic research requires reproducibility, statistical rigor, and comprehensive benchmarking, while production demands scalability, monitoring, real-time performance, and usability.

2. **Data Quality Matters More Than Model Complexity**: A perfectly balanced, well-cleaned dataset simplified training significantly - no need for complex class weighting or focal loss.

3. **Feedback Loops Are Essential**: Models only improve over time with real-world feedback. Building the infrastructure for continuous improvement is as important as the initial model.

4. **Documentation Saves Time**: With complex architecture spanning research and production, comprehensive documentation prevented hours of confusion and enabled faster iteration.

5. **Modern Deployment Tools Are Game-Changers**: Railway + Docker made deploying ML applications dramatically easier than traditional hosting approaches.

6. **Token Distribution Analysis Is Critical**: Understanding that 80.7% of samples fit in 256 tokens allowed smart trade-offs between coverage and training efficiency.

7. **Async Architecture Scales Better**: FastAPI's async capabilities and Celery's task queue enable handling multiple requests and expensive operations without blocking.

8. **Ethical Considerations Are Paramount**: Building tools for mental health detection requires careful thought about privacy, bias, false negatives, and human oversight.

---

## ğŸš€ What's Next for Mental Health Ideation

### Short-term (Month 1)
- [ ] Collect 50-100 teacher corrections through the feedback system
- [ ] Complete training of remaining transformer models (BERT, RoBERTa, ELECTRA, XLNet, DeBERTa)
- [ ] Implement hyperparameter tuning for top-performing models
- [ ] Add rate limiting and admin authentication to production API
- [ ] Create video demo and tutorial materials

### Medium-term (Quarter 1)
- [ ] Run first model retraining cycle with real teacher feedback
- [ ] Implement ensemble methods combining top-performing models
- [ ] Complete comprehensive error analysis and interpretability studies (SHAP/LIME)
- [ ] Prepare academic paper for publication with statistical validation
- [ ] Add email notifications for high-risk detections
- [ ] Expand beta testing to additional schools

### Long-term (Year 1)
- [ ] Multiple retraining cycles measuring improvement over time
- [ ] Conduct demographic bias analysis and fairness audits
- [ ] Develop mobile application version for iOS/Android
- [ ] Create comprehensive teacher training materials and best practices guide
- [ ] Explore multilingual support for non-English texts
- [ ] Partner with mental health organizations for validation studies
- [ ] Scale to districts and educational institutions nationwide

---

## ğŸ“ Project Structure

```
mental-health-ideation-detection/
â”œâ”€â”€ research/                      # ğŸ”¬ Research & Experimentation
â”‚   â”œâ”€â”€ src/                      # Training code, models, metrics
â”‚   â”œâ”€â”€ config/                   # Experiment configurations
â”‚   â”œâ”€â”€ scripts/                  # Training & evaluation scripts
â”‚   â”œâ”€â”€ results/                  # Model checkpoints & metrics
â”‚   â””â”€â”€ README.md                 # Research guide
â”‚
â”œâ”€â”€ deployment/                    # ğŸŒ Production Web Application
â”‚   â”œâ”€â”€ backend/                  # FastAPI application
â”‚   â”‚   â”œâ”€â”€ app.py               # Main API
â”‚   â”‚   â”œâ”€â”€ worker.py            # Celery tasks
â”‚   â”‚   â”œâ”€â”€ services/            # ML inference services
â”‚   â”‚   â””â”€â”€ templates/           # HTML templates
â”‚   â”œâ”€â”€ Dockerfile               # Container definition
â”‚   â”œâ”€â”€ docker-compose.yml       # Local development
â”‚   â””â”€â”€ README.md                # Deployment guide
â”‚
â”œâ”€â”€ docs/                          # ğŸ“š Documentation
â”‚   â”œâ”€â”€ RESEARCH_PLAN.md          # Research methodology
â”‚   â”œâ”€â”€ EDA_SUMMARY.md            # Data analysis
â”‚   â””â”€â”€ PUBLICATION_QUERY.md      # Publication planning
â”‚
â”œâ”€â”€ LICENSE                        # MIT License
â””â”€â”€ README.md                      # This file
```

---

## ğŸš€ Quick Start

### For Teachers (Use the App)

Visit **[mentalhealthideation.com](https://mentalhealthideation.com)** and:
1. Paste student essay text into the analyzer
2. Click "Analyze" to get real-time risk assessment
3. Review highlighted text showing concerning phrases
4. Submit feedback if the prediction is incorrect
5. Help improve the model for everyone

### For Developers (Run Locally)

```bash
# Clone the repository
git clone https://github.com/AvyayaKumar/mental-health-ideation-detection.git
cd mental-health-ideation-detection/deployment/

# Copy environment file
cp .env.example .env

# Start all services with Docker
docker-compose up

# Visit: http://localhost:8000
```

### For Researchers (Train Models)

```bash
# Navigate to research folder
cd research/

# Install dependencies
pip install -r requirements-research.txt

# Train baseline model
python src/train.py --config config/distilbert_base.yaml

# See research/README.md for detailed instructions
```

---

## ğŸ“Š Current Status

- âœ… **Trained DistilBERT baseline model** (97.96% accuracy)
- âœ… **Production web app deployed** at mentalhealthideation.com
- âœ… **Feedback loop system implemented** with PostgreSQL + Celery
- âœ… **Admin dashboard operational** for monitoring predictions
- ğŸ”„ **Additional model training in progress** (BERT, RoBERTa, ELECTRA)
- ğŸ”„ **Error analysis & interpretability studies** ongoing
- â³ **Statistical validation pending** (McNemar's tests)
- â³ **Academic publication preparation** planned

---

## ğŸ”¬ Research Methodology

**Objective**: Benchmark transformer models for suicide ideation detection with rigorous experimental methodology suitable for academic publication.

**Models Being Evaluated**:
1. DistilBERT (66M params) - âœ… Trained
2. BERT-base (110M params) - ğŸ”„ In progress
3. RoBERTa-base (125M params) - â³ Pending
4. ELECTRA-base (110M params) - â³ Pending
5. XLNet-base (110M params) - â³ Pending
6. DeBERTa-v3-base (86M params) - â³ Pending

**Key Metrics** (in priority order):
- False Negative Rate (most critical)
- F1 Score
- Recall
- Precision
- Accuracy

**Timeline**: 7-12 weeks for complete research study

See [docs/RESEARCH_PLAN.md](docs/RESEARCH_PLAN.md) for full methodology.

---

## ğŸŒ API Documentation

Interactive API documentation available at:
- **Swagger UI**: https://mentalhealthideation.com/docs
- **ReDoc**: https://mentalhealthideation.com/redoc

### Key Endpoints

```bash
# Health check
GET /health

# Analyze text
POST /api/v1/analyze
{
  "text": "Sample essay text...",
  "explain": true
}

# Submit teacher feedback
POST /api/v1/feedback
{
  "prediction_id": 123,
  "correct_class": 0,
  "teacher_notes": "Actually not concerning..."
}

# Admin dashboard
GET /admin
```

---

## ğŸ¤ Contributing

We welcome contributions! This project serves both research and production purposes.

### For Research Contributions
- Check [docs/RESEARCH_PLAN.md](docs/RESEARCH_PLAN.md) for current experiments
- Follow reproducibility guidelines (multiple seeds, configs, etc.)
- Document methodology and results thoroughly

### For Production Contributions
- Check [deployment/README.md](deployment/README.md) for architecture
- Test locally with Docker Compose before submitting PR
- Ensure backward compatibility with existing database schema

### Getting Started
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## âš ï¸ Important Notes

- **Research Data**: Not included in repository (large CSV files - 232K samples). Contact maintainer for dataset access.
- **Model Files**: Large model files (255MB) handled via Google Drive download during deployment.
- **Sensitive Data**: No actual student essays or personal data in repository.
- **Ethics**: This tool is designed to help teachers identify at-risk students for intervention, not for surveillance or punishment.
- **Limitations**: This is an assistive tool requiring human oversight. Never use as sole diagnostic criteria.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ“ Contact

**Avyaya Kumar**
- Email: avyaya.kumar@gmail.com
- GitHub: [@AvyayaKumar](https://github.com/AvyayaKumar)
- Project: [mental-health-ideation-detection](https://github.com/AvyayaKumar/mental-health-ideation-detection)

---

## ğŸ™ Acknowledgments

- **HuggingFace** for the Transformers library and pre-trained models
- **Railway** for providing excellent deployment platform
- **Google Colab** for GPU resources for research
- **FastAPI** community for the excellent web framework
- **Mental health professionals** who provided guidance on ethical considerations

---

**Built with â¤ï¸ to help save lives through AI-assisted early detection**

*Last Updated: October 2025*
